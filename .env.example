OPENAI_API_KEY=sk-SEU_TOKEN_AQUI

# Provider do LLM: 'openai' (padrão) ou 'ollama'
LLM_PROVIDER=openai

# Configuração do Ollama (se usar LLM_PROVIDER=ollama)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1

# Geração (controle de criatividade/precisão)
LLM_TEMPERATURE=0.1
LLM_TOP_P=0.9
LLM_MAX_TOKENS=256
USE_RAG_TOOL=false

# Dicas:
# - Renomeie para `.env` e mantenha fora do controle de versão.
# - O projeto carrega o .env automaticamente a partir da raiz (usa find_dotenv).
# - Para Twitter, use `config/credentials.yaml` conforme o exemplo no repositório.
